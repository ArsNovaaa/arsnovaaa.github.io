---
layout: post
title: C++
date: 2024-2-23 20:08 +0800
last_modified_at: 2025-1-17 21:08 +0800
tags: [C++, Notes]
toc:  false
---

### 虚函数表和虚函数表指针的创建

虚函数表实际是一个虚函数地址的数组，其指向为具体的代码区的位置。
- 背景：用来实现多态机制
- 生成：编译器编译的时候生成，由virtual关键字修饰。
- 存放位置：可执行程序状态下，存放在磁盘；运行状态，存放在内存中。
- 虚拟内存分区：栈区（栈区之上时内核空间）、文件映射区、堆区、数据区（静态存储区）和代码区。
可执行程序中不同部分存储的内容如下：
<table>
  <thead>
    <tr>
      <th>可执行程序中（磁盘）</th>
      <th>作用</th>
      <th>对应虚拟内存分区（内存）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>.bss</td>
      <td>未初始化的或初始化为0的全局、静态变量</td>
      <td>静态存储区</td>
    </tr>
    <tr>
      <td>.data</td>
      <td>初始化的全局、静态变量</td>
      <td>静态存储区</td>
    </tr>
    <tr>
      <td>.rodata</td>
      <td>只读数据段和虚函数表</td>
      <td>代码区</td>
    </tr>
        <tr>
      <td>.text</td>
      <td>具体代码表</td>
      <td>代码区</td>
    </tr>
  </tbody>
</table>

- <mark>虚函数表指针的创建时机：</mark>

1. <mark>类对象构造的时候，把类的虚函数表地址赋值给vptr。</mark>
2. 没有构造函数，编译器会生成默认的构造函数（有第一条的作用）。
3. 继承的情况下（例如B继承A），先调用基类的构造函数，把A的虚函数表的地址赋值给vptr。再调用子类构造函数，把B的虚函数表的地址赋值给vptr。

### 虚函数表和虚函数表指针的关系
<mark>每个类只有一个虚函数表，类的不同对象通常来说虚函数表指针vptr(每个类实例有一个)是不一样的</mark>（自身地址不一样，指向的内容一样，为深拷贝。浅拷贝会导致一个置null后另一个类实例找不到虚函数表）。使用的时候需要显式地定义拷贝构造函数或重载赋值运算符。

### 默认拷贝构造函数何时生成

**背景**
不提供的话，位拷贝，全盘复制。
- 危害1：堆上资源也会复制
- 危害2：文件句柄，socket也复制
持有相同的对象资源，句柄，一者释放，另一者就拿不到数据。

**触发默认构造函数时机**
- A b；
- A a(b);
- A a=b;
- 函数传参，形参为类对象
- 函数返回值为类对象（有返回值优化），无优化会多次调用。（C++11之后还会看是否有移动构造，然后看类有没有默认构造，再没有，报错）

**生成时间**
编译时生成。
1. 类成员变量是一个类，该成员类有默认构造函数。
2. 类继承自基类，基类有默认构造函数。
3. 类成员有虚函数。
4. 类继承自基类，基类有虚函数。

### 进程和线程的区别

本质：进程是资源费配的基本单位，线程是CPU调度的基本单位。

-  并发性：切换效率。上下文切换（如redis to mysql），运行环境（寄存器，程序计数器，用户空间信息与内核空间，pcb）。如果同一个进程的线程切换，效率高，不用动用户空间的数据。
- 内存：线程不具备独立分配虚拟内存的空间。进程有独立的地址空间。但线程有栈，pc，本地存储等独立空间。
- 所属关系：线程依附于进程，进程可以有多个线程。
- 健壮性：进程与进程之间隔离，独立的。线程共享一个进程，互相影响。进程健壮性高于线程。

### 系统调用的整个流程

- 什么是系统调用
  用户态进入内核态的一种形式。用户态需要操作到内核态的资源。
  用户程序->函数库->系统调用->内核
- 中断
  系统调用是软中断（0x80）。中断号、中断向量表、中断处理程序。
- 调用流程
  触发中断->切换堆栈->执行中断程序->从中断处理程序返回（iret软中断返回）

  {% highlight cpp %}
// 示例：通过`syscall`指令或软中断触发
int main() {
    write(1, "Hello", 5);  // 调用write系统调用
}; 
x86架构示例（通过0x80中断）
mov eax, 4     ; 系统调用号（sys_write）
mov ebx, 1     ; 文件描述符
mov ecx, msg   ; 缓冲区地址
mov edx, len   ; 数据长度
// 系统调用表示例（Linux内核）
void *sys_call_table[] = {
    [0] = sys_restart_syscall,
    [1] = sys_exit,
    [4] = sys_write,  // 对应示例中的write调用
    //...
};
// sys_write内核函数简化逻辑
asmlinkage long sys_write(
    unsigned int fd, 
    const char __user *buf, 
    size_t count
) {
    struct file *file = fget(fd);
    return vfs_write(file, buf, count, &file->f_pos);
}
// 通过iret指令恢复现场
ENTRY(ret_from_sys_call)
    RESTORE_ALL
    iret
{% endhighlight %}

-  如果使用阻塞的io且io未就绪，将线程或者进程切换，运行态->阻塞态
  
### 线程池手撕

{% highlight cpp %}
 #include <vector>
#include <thread>
#include <queue>
#include <functional>
#include <mutex>
#include <condition_variable>
#include <future>

class ThreadPool {
public:
    explicit ThreadPool(size_t threads = std::thread::hardware_concurrency()) {
        for(size_t i = 0; i < threads; ++i)
            workers.emplace_back([this] {
                for(;;) {
                    std::function<void()> task;
                    {
                        std::unique_lock<std::mutex> lock(queue_mutex);
                        condition.wait(lock, [this]{ return stop || !tasks.empty(); });
                        if(stop && tasks.empty()) return;
                        task = std::move(tasks.front());
                        tasks.pop();
                    }
                    task();
                }
            });
    }

    template<class F, class... Args>
    auto enqueue(F&& f, Args&&... args) -> std::future<decltype(f(args...))> {
        using return_type = decltype(f(args...));
        
        auto task = std::make_shared<std::packaged_task<return_type()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...)
        );
        
        std::future<return_type> res = task->get_future();
        {
            std::unique_lock<std::mutex> lock(queue_mutex);
            if(stop)
                throw std::runtime_error("enqueue on stopped ThreadPool");
            tasks.emplace([task](){ (*task)(); });
        }
        condition.notify_one();
        return res;
    }

    ~ThreadPool() {
        {
            std::unique_lock<std::mutex> lock(queue_mutex);
            stop = true;
        }
        condition.notify_all();
        for(std::thread &worker : workers)
            worker.join();
    }

private:
    std::vector<std::thread> workers;
    std::queue<std::function<void()>> tasks;
    std::mutex queue_mutex;
    std::condition_variable condition;
    bool stop = false;
};
{% endhighlight %}

## 移动语义

C++11引入了移动语义，可以减少拷贝构造函数的调用，提高效率。
对象移动时，会将对象内的资源转移到另一个对象，而不是拷贝。避免资源的重新分配。

- 移动构造函数：将右值对象内的资源转移到左值对象内。
- 移动赋值运算符：将右值对象内的资源转移到左值对象内。

{% highlight cpp %}
class A {
public:
    A(A&& other) noexcept {
        std::cout << "move constructor" << std::endl;
        // 资源转移
        data = other.data;
        other.data = nullptr;
    }
    A& operator=(A&& other) noexcept {
        std::cout << "move assignment operator" << std::endl;
        if(this!= &other) {
            // 资源转移
            data = other.data;
            other.data = nullptr;
        }
        return *this;
    }
    A(const A& other) {
        std::cout << "copy constructor" << std::endl;
        // 拷贝构造
        data = new int(other.data);
    }
    A& operator=(const A& other) {
        std::cout << "copy assignment operator" << std::endl;
        if(this!= &other) {
            // 拷贝赋值
            delete data;
            data = new int(other.data);
        }
        return *this;
    }
    ~A() {
        std::cout << "destructor" << std::endl;
        delete data;
    }
    int* data;
};

int main() {
    A a1(10);
    A a2(std::move(a1)); // 移动构造
    A a3 = std::move(a2); // 移动赋值
    return 0;
}
{% endhighlight %}

输出：
```
move constructor
move constructor
move assignment operator
destructor
destructor
```

### 移动语义在stl中的应用
- std::move：将左值转换为右值。
- std::forward：将参数类型转换为右值引用。
- std::move_if_noexcept：判断类型是否支持移动语义。
- std::swap：交换两个对象内的资源。

## 完美转发

在模板中，将模板参数完美地转发到内部函数（内部调用）参数中去。转发时保证被转发的参数的值属性不变。

{% highlight cpp %}
template<typename F, typename... Args>
auto invoke(F&& f, Args&&... args) -> decltype(std::forward<F>(f)(std::forward<Args>(args)...)) {
    return std::forward<F>(f)(std::forward<Args>(args)...);
}

{% endhighlight %}

- 借用万能引用，模板参数T或者auto，即需要类型推导，来接受左右属性。
- 应用折叠规则，模板参数T&&，即右值引用。T为左值或者左值引用，转为左值引用。T为右值或者右值引用，转为右值引用。（例如int& &&->int&，int&& &&->int&&,int &&->int &）
- 无论是左值引用还是右值引用，都是左值，具名。左值和右值是指对象是否拥有资源的这个本质（或者叫属性），而不是对象的值。
- std::forward<T>(v)：T为左值引用，v将转化为T类型的左值。T为右值引用，v将转化为T类型的右值。去除了引用，转化为T类型的对象。

## 智能指针

- 指针管理困境：
  - 资源释放问题：指针失效，资源泄露。
  - 资源管理问题：资源泄露，资源管理复杂。（重复释放，释放时机不确定，释放顺序不确定）
- 如何解决：智能指针。RAII（Resource Acquisition Is Initialization）思想。根据对象的生命周期进行资源的控制。
- shared_ptr实现原理：
  - 引用计数：每个对象维护一个引用计数，当引用计数为0时，释放资源。
  - 自动释放：智能指针管理的资源，在离开作用域时自动释放。
  - 异常安全：智能指针保证异常安全，即使在构造函数或析构函数中抛出异常，也能保证资源的正确释放。
- 常见智能指针：
  - unique_ptr：独占所有权，只能有一个指针指向对象。
  - shared_ptr：共享所有权，多个指针指向对象。
  - weak_ptr：弱引用，指向shared_ptr对象，但不影响引用计数。


## 单例模式C++11之后的最佳解决————Meyers' Singleton
对于local static 对象，其初始化发生在控制流第一次执行到该对象的初始化语句时。多个线程的控制流可能同时到达其初始化语句。

在C++11之前，在多线程环境下local static对象的初始化并不是线程安全的。具体表现就是：如果一个线程正在执行local static对象的初始化语句但还没有完成初始化，此时若其它线程也执行到该语句，那么这个线程会认为自己是第一次执行该语句并进入该local static对象的构造函数中。这会造成这个local static对象的重复构造，进而产生内存泄露问题。所以，local static对象在多线程环境下的重复构造问题是需要解决的。

而C++11则在语言规范中解决了这个问题。C++11规定，在一个线程开始local static 对象的初始化后到完成初始化前，其他线程执行到这个local static对象的初始化语句就会等待，直到该local static 对象初始化完成。

Meyers Singleton的实现：
{% highlight cpp %}
class Singleton
{
private:
	Singleton() { };
	~Singleton() { };
	Singleton(const Singleton&);
	Singleton& operator=(const Singleton&);
public:
	static Singleton& getInstance() 
        {
		static Singleton instance;
		return instance;
	}
};
{% endhighlight %}


## 模板工厂模式

- 该模式用来封装和管理类的创建，终极目的是为了解耦，实现创建者和调用者的分离。
- 这里贴一段之前在实习公司的项目中的实现，十分精简，感觉很有借鉴意义。比目前我在网上看到的类似实现都要好。
{% highlight cpp %}
template <class ProductClass, typename... ArgType>
void* objCreateFunc(ArgType... arg)
{
    return new ProductClass(arg...);
}

#ifndef ReflectRegister
#    define ReflectRegister(ProductClass, ...) \
        static int __type##ProductClass =      \
            ReflectFactory::registerObjCreateFunc(#ProductClass, (void*)&objCreateFunc<ProductClass, ##__VA_ARGS__>);
#endif

class ReflectFactory
{
public:
    template <class BaseClass, typename... ArgType>
    static BaseClass* createObj(const std::string& className, ArgType... arg)
    {
        typedef BaseClass* (*_CreateFactory)(ArgType...);

        auto& _funcMap = getObjCreateFuncMap();
        auto iFind = _funcMap.find(className);
        if (iFind == _funcMap.end())
            return nullptr;
        else
            return reinterpret_cast<_CreateFactory>(_funcMap[className])(arg...);
    }

    static int registerObjCreateFunc(const std::string& className, void* func)
    {
        getObjCreateFuncMap()[className] = func;
        return 0;
    }

private:
    static std::unordered_map<std::string, void*>& getObjCreateFuncMap()
    {
        static std::unordered_map<std::string, void*> s_classRefectionMap;
        return s_classRefectionMap;
    }
};

{% endhighlight %}

- 这里reinterpret_cast<_CreateFactory>(_funcMap[className])(arg...);转换的时void* objCreateFunc(ArgType... arg)这个函数指针，将它的返回值变成了父类指针，但是具体执行的时候return new ProductClass(arg...);还是创建了子类对象，实现了多态！

## 环形缓冲区

环形缓冲区是一种数据结构，它可以实现在一段连续的内存中存储和读取数据，但是只能以一种循环的方式来访问。

环形缓冲区的实现原理：
- 环形缓冲区由一个缓冲区数组和两个指针组成。
- 缓冲区数组中存储的数据是环形的，即缓冲区数组的首尾相连。
- 两个指针：
  - read_ptr：指向当前读入缓冲区的位置。
  - write_ptr：指向下一个待写入缓冲区的位置。
- 读操作：
  - 读操作从缓冲区中读取数据，首先从read_ptr指向的位置开始读取，直到缓冲区的末尾，然后从缓冲区的开头开始读取，直到read_ptr指向的位置。
  - 读操作完成后，read_ptr指向下一个待读取的位置。
- 写操作：
  - 写操作向缓冲区中写入数据，首先将数据写入write_ptr指向的位置，然后将write_ptr指向下一个位置。
  - 如果写操作导致缓冲区的末尾被覆盖，则将缓冲区的开头到末尾的数据拷贝到缓冲区的开头，然后将write_ptr指向缓冲区的开头。
  - 写操作完成后，write_ptr指向下一个待写入的位置。

环形缓冲区的优点：
- 环形缓冲区可以实现数据的循环读写，即使缓冲区的容量不足，也可以循环使用。
- 环形缓冲区可以实现数据的异步读写，即使读写操作发生在不同的线程中，也可以保证数据的完整性。
- 环形缓冲区可以实现数据的缓冲，即使数据生产的速度远远大于消费的速度，也可以缓冲数据。

## 手撕ringbuffer

{% highlight cpp %}
#include <iostream>
#include <mutex>
#include <condition_variable>

template<typename T>
class RingBuffer {
public:
    RingBuffer(size_t size) : m_size(size), m_buffer(new T[size]), m_read_pos(0), m_write_pos(0) {}
    ~RingBuffer() { delete[] m_buffer; }

    bool push(const T& data) {
        std::unique_lock<std::mutex> lock(m_mutex);
        if (isFull()) {
            return false;
        }
        m_buffer[m_write_pos] = data;
        m_write_pos = (m_write_pos + 1) % m_size;
        m_cv.notify_one();
        return true;
    }

    bool pop(T& data) {
        std::unique_lock<std::mutex> lock(m_mutex);
        if (isEmpty()) {
            return false;
        }
        data = m_buffer[m_read_pos];
        m_read_pos = (m_read_pos + 1) % m_size;
        m_cv.notify_one();
        return true;
    }

    bool peek(T& data) {
        std::unique_lock<std::mutex> lock(m_mutex);
        if (isEmpty()) {
            return false;
        }
        data = m_buffer[m_read_pos];
        return true;
    }

    bool isFull() const {
        return (m_write_pos + 1) % m_size == m_read_pos;
    }

    bool isEmpty() const {
        return m_read_pos == m_write_pos;
    }

private:
    size_t m_size;
    T* m_buffer;
    size_t m_read_pos;
    size_t m_write_pos;
    std::mutex m_mutex;
    std::condition_variable m_cv;
};

{% endhighlight %}

## 内存对齐的ringbuffer


{% highlight cpp %}
#include <iostream>
#include <mutex>
#include <condition_variable>

template<typename T, size_t ALIGNMENT = 64>
class AlignedRingBuffer {
public:
    AlignedRingBuffer(size_t size) : m_size(size), m_buffer(new char[size * sizeof(T) + ALIGNMENT]), m_read_pos(0), m_write_pos(0) {
        m_buffer = (T*)(((size_t)m_buffer + ALIGNMENT - 1) & ~(ALIGNMENT - 1));
    }
    ~AlignedRingBuffer() { delete[] m_buffer; }

    bool push(const T& data) {
        std::unique_lock<std::mutex> lock(m_mutex);
        if (isFull()) {
            return false;
        }
        *(T*)(m_buffer + m_write_pos) = data;
        m_write_pos = (m_write_pos + 1) % m_size;
        m_cv.notify_one();
        return true;
    }

    bool pop(T& data) {
        std::unique_lock<std::mutex> lock(m_mutex);
        if (isEmpty()) {
            return false;
        }
        data = *(T*)(m_buffer + m_read_pos);
        m_read_pos = (m_read_pos + 1) % m_size;
        m_cv.notify_one();
        return true;
    }

    bool peek(T& data) {
        std::unique_lock<std::mutex> lock(m_mutex);
        if (isEmpty()) {
            return false;
        }
        data = *(T*)(m_buffer + m_read_pos);
        return true;
    }

    bool isFull() const {
        return (m_write_pos + 1) % m_size == m_read_pos;
    }

    bool isEmpty() const {
        return m_read_pos == m_write_pos;
    }

private:
    size_t m_size;
    char* m_buffer;
    size_t m_read_pos;
    size_t m_write_pos;
    std::mutex m_mutex;
    std::condition_variable m_cv;
};

{% endhighlight %}

## 缓存一致性

缓存一致性（Cache Coherency）是指多个CPU或多个处理器共享同一块内存，当其中一个处理器对内存进行修改时，其他处理器需要知道这个修改，并将其缓存中的数据更新。缓存一致性保证了共享内存的正确性，是计算机系统的重要组成部分。

缓存一致性协议：MESI协议，基于总线嗅探，实现了十五的串行化。

- M（Modified）：缓存行中的数据被修改，但还没有被写回主存。
- E（Exclusive）：缓存行中的数据被独占使用，其他处理器不能访问。
- S（Shared）：缓存行中的数据可以被多个处理器共享。
- I（Invalid）：缓存行中的数据无效，需要从主存中重新加载。

MESI协议的特点：
- 缓存行的大小一般为64字节。
- 缓存行的状态变化必须通过总线嗅探来通知其他处理器。
- 缓存行的状态变化必须遵循先行发生原则。
- 缓存行的状态变化必须遵循容许延迟的原则。
- 缓存行的状态变化必须遵循写回策略。
- 缓存行的状态变化必须遵循写直达的原则。
- 缓存行的状态变化必须遵循写回拒绝的原则。
- 缓存行的状态变化必须遵循失效拒绝的原则。

CPU 在读写数据的时候，都是在 CPU Cache 读写数据的，原因是 Cache 离 CPU 很近，读写性能相比内存高出很多。对于 Cache 里没有缓存 CPU 所需要读取的数据的这种情况，CPU 则会从内存读取数据，并将数据缓存到 Cache 里面，最后 CPU 再从 Cache 读取数据。

而对于数据的写入，CPU 都会先写入到 Cache 里面，然后再在找个合适的时机写入到内存，那就有「写直达」和「写回」这两种策略来保证 Cache 与内存的数据一致性：

- 写直达，只要有数据写入，都会直接把数据写入到内存里面，这种方式简单直观，但是性能就会受限于内存的访问速度。
- 写回，当缓存行中的数据被修改，并通知其他 CPU 后，缓存行的状态就会变成「M」，这时缓存行中的数据就被标记为「脏」，然后 CPU 就开始将缓存行中的数据写入到内存中，写入完成后，缓存行的状态就会变成「S」，其他 CPU 就可以从内存中读取数据了。写回，对于已经缓存在 Cache 的数据的写入，只需要更新其数据就可以，不用写入到内存，只有在需要把缓存里面的脏数据交换出去的时候，才把数据同步到内存里，这种方式在缓存命中率高的情况，性能会更好。
当今 CPU 都是多核的，每个核心都有各自独立的 L1/L2 Cache，只有 L3 Cache 是多个核心之间共享的。所以，我们要确保多核缓存是一致性的，否则会出现错误的结果。

要想实现缓存一致性，关键是要满足 2 点：
- 第一点是写传播，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心。
- 第二点是事物的串行化，这个很重要，只有保证了这个，次啊能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的。

基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。
MESI 协议，是已修改、独占、共享、已实现这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。
